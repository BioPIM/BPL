%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{First steps}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{A first example}

\subsection{Task and launcher}

As an introduction, here is a small program using the \BPL that illustrates the overall philosophy of the library.
This program simply computes the sum of the elements of an input integer vector.
To do so, one must implement a struct or class that provides a method performing the actual computation; this method is an overload of the 
\cxx{operator()} function.
In the following, we will often refer to such a structure as a \textbf{task}. In this example, the task is a structure named \cxx{Sum}.

\begin{minted}[bgcolor=bg]{c++}
template<typename ARCH>
struct Sum
{
    USING(ARCH);

    int32_t operator() (vector<int32_t> const& in) const 
    {
        int32_t result = 0 ;
        for (auto n : in)  { result += n; }
        return result ;
    }
} ;
\end{minted}

For the moment, we do not discuss the \cxx{USING} macro, which will be explained later.

A few important preliminary remarks:
\begin{itemize}
	
	\item The \cxx{Sum} struct must be templated with a parameter \cxx{ARCH} that represents the hardware architecture on which the task will be executed. As a consequence, the implementation of the task should be agnostic with respect to the actual architecture that will ultimately be used.  
	Following this approach, the task can, in theory, be executed on potentially very different kinds of hardware architectures.

	\item The code itself is rather straightforward: it receives an \cxx{in} vector as an argument, which is iterated over while updating the overall sum of its elements.  
	The important point here is that the only data\footnote{There may be some exceptions to this remark.} that can be processed by the task are the input arguments of the \cxx{operator()} method; for instance, there is no way to retrieve data from a file in a filesystem.  
	On the other hand, the body of the task may define new objects (allocated on the execution stack) that can be returned if needed, such as the \cxx{result} variable holding the output of the task.

	\item Since we aim to design fast algorithms, we may want to leverage parallelization features such as threads on a multicore architecture.  
	Note that, from the task’s point of view (here, our \cxx{Sum} struct), there is no reference to threads or other parallelization mechanisms; the parallelization scheme is handled at another level.  
	In other words, the task is agnostic with respect to its own parallelization: it simply receives input data, processes it, and returns a result.

	\item The \BPL requires that the task (the \cxx{Sum} struct in our example) be placed in a header file following a specific naming convention.  
	That is, the header file must be named \cxx{X.hpp} if the structure is named \cxx{X}. In our example, the header file must therefore be named \cxx{Sum.hpp}.
\end{itemize}

Once we have written our \cxx{Sum} task, the \BPL provides mechanisms to use it, that is, to invoke it and retrieve a result.
To do so, the \BPL introduces the concept of a \textbf{launcher}, an object that takes as parameters a task (via the name of the structure that implements its logic) and the input arguments to be processed.

This is achieved through the \cxx{bpl::Launcher} class.
This class is responsible for handling the hardware architecture to be used; therefore, when creating a launcher, it must be instantiated with a template argument representing the target hardware architecture.
For instance, if we want to use a multicore architecture, we would write
\begin{minted}[bgcolor=bg]{c++}
Launcher<ArchMulticore> launcher;
\end{minted}

If we want to use an \UPMEM architecture, we would write
\begin{minted}[bgcolor=bg]{c++}
Launcher<ArchUpmem> launcher;
\end{minted}

At this point, we are done with specifying the hardware architecture to be used: it is defined through the instantiation of the \cxx{Launcher}, and only there.

To run our \cxx{Sum} task, we use the \cxx{run} method of the \cxx{Launcher} class.
\begin{minted}[bgcolor=bg]{c++}
vector<int32_t> myvector = {1,2,3,5,8};
auto results = launcher.run<Sum> (myvector);
\end{minted}

Note the following:
\begin{itemize}
  \item The task to be executed is provided as a template argument to the \cxx{Launcher::run} method.
  \item The arguments (\cxx{myvector} in the example) are passed as parameters to the instantiated version of \cxx{Launcher::run}.
  \item The result of the execution of \cxx{Sum::operator()} is retrieved in the \cxx{results} variable.  
  At this point, note the \emph{s} in \cxx{results}: it turns out that multiple results can be retrieved, rather than a single one
  (i.e., a simple \cxx{int32\_t} in our \cxx{Sum} example).
\end{itemize}


To run this example, we can put everything into a \cxx{main.cpp} file containing the following code:
\begin{minted}[bgcolor=bg]{c++}
#include <bpl/bpl.hpp>
#include <Sum.hpp>
#include <vector>

int main()
{
    std::vector<int32_t> myvector = {1,2,3,5,8};

    bpl::Launcher<bpl::ArchMulticore> launcher;
    auto results = launcher.run<Sum> (myvector);
    
    return 0 ;
}
\end{minted}
Note the inclusion of the \cxx{bpl.hpp} file to use the API of the \cxx{Launcher} class.
We also need to include the \cxx{Sum.hpp} file, where our task is defined; indeed, this definition is required in order to call the \cxx{Launcher::run} method with \cxx{Sum} as a template argument.

A one-liner version would be
\begin{minted}[bgcolor=bg]{c++}
#include <bpl/bpl.hpp>
#include <Sum.hpp>
#include <vector>

int main()
{
    auto results = bpl::Launcher<bpl::ArchMulticore>{}.run<Sum> (
        std::vector<int32_t> {1,2,3,5,8}
    );
    return 0 ;
}
\end{minted}

Note that we could have used a different architecture when declaring our launcher, for instance by using \cxx{ArchUpmem} instead:
\begin{minted}[bgcolor=bg]{c++}
#include <bpl/bpl.hpp>
#include <Sum.hpp>
#include <vector>

int main()
{
    auto results = bpl::Launcher<bpl::ArchUpmem>{}.run<Sum> (
        std::vector<int32_t> {1,2,3,5,8});
    return 0 ;
}
\end{minted}

Now, our program can be compiled using the CMake tool. In fact, the \BPL provides a compilation toolchain that hides many low-level details; this toolchain is an important part of the \BPL and will be described in detail later.

From the end-user’s perspective, everything we have seen so far resembles regular C++ development.
We implement a small algorithm (summing the items of a vector) as a functor—that is, a struct with an overloaded \cxx{operator()} method.
We then use the \cxx{bpl::Launcher} class to run it. Nothing in our code is specific to low-level details of the \UPMEM architecture, for example; everything is handled by the \BPL itself.
On the other hand, we have not yet discussed how to parallelize our algorithm to take full advantage of the underlying hardware architecture.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Parallelization}

Modern hardware architectures can greatly speed up programs by parallelizing algorithms; for example, by splitting an algorithm into small pieces that can be processed simultaneously and then aggregating the final result from the results of each piece.

In multicore architectures, this is often achieved using the well-known concept of a thread. Broadly speaking, using 
N threads can potentially divide the execution time of an algorithm by 
N, since each thread can run on a specific CPU of the underlying architecture.
On the other hand, the \UPMEM architecture uses the concept of a tasklet, which is similar at first glance to a thread but with significant differences that we will examine later.
For now, we introduce the concept of a \textbf{process unit} to unify both concepts of thread and tasklet—that is, an entity that can execute a portion of a program on part of the underlying hardware architecture.

One of the main challenges in designing the \BPL was to allow developers to write a single codebase that can run on different architectures (currently mainly multicore CPUs and \UPMEM).
This means that, when implementing a task, the underlying architecture is known only through the template parameter \cxx{ARCH}, so no assumptions should be made about a specific architecture.
It is only when a \cxx{bpl::Launcher} is declared with a specific architecture and the \cxx{Launcher::run} method is called for the target class that all the specifics of the underlying architecture are taken into account.

Consequently, the \BPL design had to accommodate different parallelization schemes, both for multicore and \UPMEM environments.
This is the role of the \cxx{bpl::Launcher} class: a launcher not only knows about the underlying architecture but also knows how to parallelize the task for the target architecture.

Another consideration is how many resources we want to allocate to run our task. On a 32-core architecture, for example, we might want to use only 8 cores.
This can be achieved by providing the number of process units (threads, in this case) to use as an argument to the constructor of \cxx{bpl::Launcher}.

\begin{minted}[bgcolor=bg]{c++}
Launcher<ArchMulticore> launcher (Thread{8});
\end{minted}
which can also be writen with
\begin{minted}[bgcolor=bg]{c++}
// launcher will use 8 process units (i.e. threads)
Launcher<ArchMulticore> launcher (8_thread);  
\end{minted}
So 8 threads will be used when calling \verb+launcher.run<Sum>(myvector)+, each performing the same summation on the input vector.

When using the \UPMEM architecture, it is possible to specify the amount of resources by setting the number of ranks or DPUs, e.g.,
\begin{minted}[bgcolor=bg]{c++}
// launcher1 will use 20*64*16 process units (i.e. tasklets)
Launcher<ArchUpmem> launcher1 (20_rank);  
// launcher2 will use 500*16 process units (i.e. tasklets)
Launcher<ArchUpmem> launcher2 (500_dpu);   
\end{minted}

What we have just done is define how many resources a launcher can use and the corresponding number of process units running the task.
However, each process unit will process the same input data and therefore produce the same result.
We now need to specify how to parallelize the algorithm. The \BPL provides a solution by splitting the input arguments of the task and assigning each specific split to a dedicated process unit.
In our example, the input vector \cxx{in} will be divided into sub-vectors, and each sub-vector (potentially empty) will be provided as an argument to a separate instantiation of the \cxx{Sum} structure—one per process unit.
This parallelization scheme can be easily applied by wrapping the \cxx{myvector} argument with the \cxx{bpl::split} method.
\begin{minted}[bgcolor=bg]{c++}
auto results = launcher.run<Sum> (split(myvector));
\end{minted}

Now, a word about the 's' in \cxx{results}: each process unit runs an instance of \cxx{Sum} and produces a result.
Therefore, if we have N process units, \cxx{results} will be a vector of 
N \verb+int32_t+ objects\footnote{Note that \cxx{results} could be any iterable type rather than a full-fledged vector.}.
Thus, we could write
\begin{minted}[bgcolor=bg]{c++}
// Iterate over the result of each process unit
for (auto result : launcher.run<Sum> (split(myvector)))  
{ 
    /* do something with result */ 
}
\end{minted}

We will see later that \cxx{bpl::split} can be (template) parameterized to achieve more specific behavior. For now, we just keep in mind the default parallelization model of the \BPL: the task itself does not know about parallelization; it is up to the end user (through the launcher) to provide a specific portion of the data that will feed each instance of the task running on a given process unit.

Note that this model is quite simple and may not be sufficient for every parallelization scheme. Other models could be proposed in the future.

We have now briefly covered some of the main concepts of the \BPL, such as tasks and launchers. Next, we will go a step further by retrieving the \BPL, creating a new \BPL project, and compiling it.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Getting and using the \BPL}

\subsection{Requirements}
Since one of the main target architectures of the \BPL is the \UPMEM architecture, you should install the \UPMEM SDK. In particular, the \BPL works with version 2023.2 (see \verb+https://sdk.upmem.com+
), so it is recommended to use this version.

Once installed, you need to define the \verb+UPMEM_HOME+ environment variable to point to the \UPMEM SDK, for example:
\begin{verbatim}
    UPMEM_HOME=/opt/upmem-2023.2.0
\end{verbatim}
 
You should also have a recent \verb+C/C+++ compiler installed on your system that supports at least C++20.

\subsection{Getting the \BPL}

Currently, the simplest way to obtain the \BPL is to clone the following Git repository:
\begin{verbatim}
https://github.com/BioPIM/BPL.git
\end{verbatim}

Once the repository has been cloned, you can do the following to build the unit tests from the cloned directory:
\begin{itemize}
  \item mkdir build
  \item cd build
  \item cmake ..
  \item make
\end{itemize}
During the build, you should see a message instructing you to set the \verb+DPU_BINARIES_DIR+ environment variable to a specific value.
This is mandatory in order to run the unit tests, because the \BPL needs to know where the binaries generated for the \UPMEM architecture are located (more on this later).

The unit tests\footnote{The unit tests are based on the \cxx{Catch2} framework} can be launched from the build directory as follows:
\begin{verbatim}
./test/unit/host/bpl-unittests.host
\end{verbatim}

\subsection{Creating a project from scratch}

It is possible to write a new program from this content, but this repository is primarily focused on the development of the library itself.
A useful way to create an independent \BPL project is to generate a \verb+tar.gz+ archive containing the minimal source code and \cxx{CMake} files required to build a \BPL project that can run on both multicore and \UPMEM architectures.

To do this, you can use \cxx{CMake} while specifying the name of your project. For example, if you want to name your project \cxx{MyProject}, you would do the following:
\begin{verbatim}
cmake -DNEWPROJECT_NAME=MyProject ..
\end{verbatim}
This will add a specific target, \verb+create_bpl_project_MyProject+, and the project can then be generated with:
\begin{verbatim}
make create_bpl_project_MyProject
\end{verbatim}
This will produce a \verb+MyProject.tar.gz+ archive containing the minimal resources for your project. You can then do:
\begin{enumerate}
  \item \verb+tar xvfz MyProject.tar.gz+
  \item \verb+cd MyProject+
  \item \verb+mkdir build+
  \item \verb+cd build+
  \item \verb+cmake ..+
  \item \verb+make+
\end{enumerate}
Don’t forget to set the \verb+DPU_BINARIES_DIR+ environment variable as indicated in the build output. You can then run the program with:
\begin{verbatim}
./src/main/MyProject
\end{verbatim}

\subsection{Compilation toolchain with the \BPL}
The \BPL aims to make the code agnostic with respect to the underlying architecture. This can be quite challenging for architectures like \UPMEM. Normally, a developer would have to write two programs: one for the host using standard C/C++, and one for the DPU chipset using the \UPMEM SDK.
With the \BPL, the developer does not need to worry about these details and can focus on writing a single codebase.
To achieve this, the \BPL provides a compilation toolchain based on \emph{CMake}, which handles the generation of the two binaries (one for the host and one for the DPU) whenever the \UPMEM architecture is targeted.

This compilation toolchain requires that the developer follow certain conventions:
\begin{enumerate}
\item The task is implemented as a functor, i.e., a structure that defines an \cxx{operator()} method performing the computation.
\item This structure is templated, with a \cxx{ARCH} template parameter representing the target hardware architecture.
\item The structure must be implemented in a \cxx{.hpp} file named after the structure; that is, if the structure is named \cxx{X}, the header file must be named \cxx{X.hpp} and placed in the \cxx{src/tasks} directory.
\item The task’s \cxx{operator()} method can take input parameters; these parameters are the only data the task can process.
\item The task is invoked through the \cxx{bpl::Launcher} class and its \cxx{run} method.
\item The launcher can be defined, for instance, in the program’s \cxx{main} function or in any source file located in the \cxx{src/main} directory.
\item The \cxx{bpl::Launcher} class takes the target hardware architecture as a template parameter (e.g., multicore, \UPMEM, etc.); additional arguments can be provided to the constructor to define the resources to use (number of threads, tasklets, etc.).
\item Normally, the only place where a hardware architecture is explicitly referenced is when instantiating the \cxx{bpl::Launcher} class; all other code should not rely on architecture-specific details.
\item When $N$ process units are used, the \cxx{bpl::split} function can be applied to one or more input arguments, splitting each argument so that each process unit receives a specific portion as input.
\end{enumerate}

In brief, the toolchain assumes that task-related code is placed in the \cxx{src/tasks} directory,
and launcher-related code for running one or more tasks is placed in the \cxx{src/main} directory.
Based on this structure, the \BPL can generate the required binaries: one for the multicore architecture, and one plus $N$ (where $N$ is the number of tasks) when targeting the \UPMEM architecture.

\subsection{Implementing a task with the \BPL}
As noted earlier, a task is a templated structure that looks like
\begin{minted}[bgcolor=bg]{c++}
template<typename ARCH>
struct Sum
{
    USING(ARCH);
    int32_t operator() (vector<int32_t> const& in) const 
    {
        int32_t result = 0 ;
        for (auto n : in)  { result += n; }
        return result ;
    }
} ;
\end{minted}
At first glance, it looks like standard C++, but a closer look raises a question: what is the actual class for \cxx{vector}?
We are not referring here to the \cxx{std::vector} class (assuming we have not used \cxx{using namespace std} earlier), so the compiler would report an error indicating that \cxx{vector} is unknown.

A type such as \cxx{std::vector} normally relies on dynamic allocation (i.e., \cxx{new/delete}).
This is not possible on the \UPMEM architecture, so if we want a class that behaves like \cxx{std::vector}, we must provide a specific implementation from another namespace rather than \cxx{std}.
In fact, the actual \cxx{vector} class should depend on the template parameter \cxx{ARCH}, so one could write something like
\begin{minted}[bgcolor=bg]{c++}
template<typename ARCH>
struct Sum
{
    int32_t operator() (ARCH::vector<int32_t> const& in) const 
    { /* same as before */ }
} ;
\end{minted}
This will not compile, and the correct type for \cxx{in} should instead be:
\begin{minted}[bgcolor=bg]{c++}
typename ARCH::vector<int32_t> const& 
\end{minted}
This is somewhat verbose. To avoid this, one can use the \cxx{USING} macro, which acts like a \cxx{using} directive for a set of predefined types.
With the \cxx{USING} macro, it becomes possible to skip prefixing each type (such as \cxx{vector}) with \cxx{ARCH}
\footnote{Technically, we are not using namespaces here as in \cxx{using namespace}, but rather defining type aliases.},
and we can write something like
 \begin{minted}[bgcolor=bg]{c++}
template<typename ARCH>
struct Sum
{
    USING(ARCH);
    int32_t operator() (vector<int32_t> const& in) const 
    { /* same as before */ }
};
\end{minted}
In this example, \cxx{std::vector} will be used when targeting a multicore architecture, while \cxx{bpl::vector} will be used for the \UPMEM architecture.
Here, \cxx{bpl::vector} is a specific implementation that handles the lack of dynamic allocation on \UPMEM.
Note, however, that \cxx{bpl::vector} implements only a subset of the methods available in \cxx{std::vector}.
Therefore, one should rely only on this subset to ensure that the task code remains compatible with both multicore and \UPMEM architectures.

This remark highlights an important caveat for the \BPL: the goal is to have a single codebase that works across different architectures, but this comes at a cost.
While it is convenient to use data structures like \cxx{vector} in a uniform way, it is not always possible to maintain identical semantics between multicore and \UPMEM implementations.
For example, methods in \cxx{std::vector} that rely on exceptions cannot be used on \UPMEM, as exceptions are not supported there.
As a result, functional differences may occur when running such methods on multicore versus \UPMEM architectures.
